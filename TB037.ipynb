{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cc6b22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn                # Baru (untuk Model)\n",
    "import torch.optim as optim          # Baru (untuk Optimizer)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset # Baru (Ganti TensorDataset)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb1fa677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah data per kelas:\n",
      "54\n",
      "1    211840\n",
      "2    283301\n",
      "3     35754\n",
      "4      2747\n",
      "5      9493\n",
      "6     17367\n",
      "7     20510\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"covtype.data\", header=None)\n",
    "\n",
    "# Label pada kolom terakhir\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "print(\"Jumlah data per kelas:\")\n",
    "print(y.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06d9283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('covtype.data', header=None)\n",
    "\n",
    "#dikurangin kolom terakhir (karena itu label)\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "#nilai label dikurang 1\n",
    "y = y - 1 \n",
    "\n",
    "#Training set 70%\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "#Validation set 15%\n",
    "#Test set 15%\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df42413a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train:\n",
      "  Class 0: 148288\n",
      "  Class 1: 198310\n",
      "  Class 2: 25028\n",
      "  Class 3: 1923\n",
      "  Class 4: 6645\n",
      "  Class 5: 12157\n",
      "  Class 6: 14357\n",
      "Total = 406708\n",
      "\n",
      "Validation:\n",
      "  Class 0: 31776\n",
      "  Class 1: 42495\n",
      "  Class 2: 5363\n",
      "  Class 3: 412\n",
      "  Class 4: 1424\n",
      "  Class 5: 2605\n",
      "  Class 6: 3077\n",
      "Total = 87152\n",
      "\n",
      "Test:\n",
      "  Class 0: 31776\n",
      "  Class 1: 42496\n",
      "  Class 2: 5363\n",
      "  Class 3: 412\n",
      "  Class 4: 1424\n",
      "  Class 5: 2605\n",
      "  Class 6: 3076\n",
      "Total = 87152\n"
     ]
    }
   ],
   "source": [
    "def show_class_distribution(name, y):\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(f\"\\n{name}:\")\n",
    "    total = counts.sum()\n",
    "    \n",
    "    for u, c in zip(unique, counts):\n",
    "        print(f\"  Class {u}: {c}\")\n",
    "    \n",
    "    print(f\"Total = {total}\")\n",
    "\n",
    "show_class_distribution(\"Train\", y_train)\n",
    "show_class_distribution(\"Validation\", y_val)\n",
    "show_class_distribution(\"Test\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2b9cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalisasi data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val   = scaler.transform(X_val)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f300d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForestCoverDataset(Dataset):\n",
    "    #data mentah --> tensor\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    #jumlah data\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    #ambil 1 data\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "#Objek dataset\n",
    "train_dataset = ForestCoverDataset(X_train, y_train)\n",
    "val_dataset   = ForestCoverDataset(X_val, y_val)\n",
    "test_dataset  = ForestCoverDataset(X_test, y_test)\n",
    "\n",
    "#DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f94497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            #layer input (input 54)\n",
    "            #hidden layer 1 (128 neuron)\n",
    "            nn.Linear(54, 128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            #hidden layer 2 (64 neuron)\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            #output layer (7 kelas)\n",
    "            nn.Linear(64, 7)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "model = Network()\n",
    "criterion = nn.CrossEntropyLoss() #loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003) #learning rate 0.003\n",
    "# Berdasarkan serangkaian eksperimen hyperparameter tuning, Learning Rate (LR) sebesar 0.003 \n",
    "# ditetapkan sebagai konfigurasi paling optimal untuk model ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ede2a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 | Loss: 0.5172 | Val Acc: 0.8181\n",
      "Epoch 2/15 | Loss: 0.4107 | Val Acc: 0.8394\n",
      "Epoch 3/15 | Loss: 0.3654 | Val Acc: 0.8501\n",
      "Epoch 4/15 | Loss: 0.3432 | Val Acc: 0.8584\n",
      "Epoch 5/15 | Loss: 0.3279 | Val Acc: 0.8672\n",
      "Epoch 6/15 | Loss: 0.3150 | Val Acc: 0.8670\n",
      "Epoch 7/15 | Loss: 0.3067 | Val Acc: 0.8718\n",
      "Epoch 8/15 | Loss: 0.2986 | Val Acc: 0.8795\n",
      "Epoch 9/15 | Loss: 0.2928 | Val Acc: 0.8779\n",
      "Epoch 10/15 | Loss: 0.2895 | Val Acc: 0.8788\n",
      "Epoch 11/15 | Loss: 0.2844 | Val Acc: 0.8804\n",
      "Epoch 12/15 | Loss: 0.2808 | Val Acc: 0.8821\n",
      "Epoch 13/15 | Loss: 0.2761 | Val Acc: 0.8833\n",
      "Epoch 14/15 | Loss: 0.2724 | Val Acc: 0.8874\n",
      "Epoch 15/15 | Loss: 0.2688 | Val Acc: 0.8843\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Training Phase\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()       # Reset gradient\n",
    "        outputs = model(inputs)     # Forward\n",
    "        loss = criterion(outputs, labels) # Hitung error\n",
    "        loss.backward()             # Backward\n",
    "        optimizer.step()            # Update bobot\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    # Validation Phase (Cek performa)\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {running_loss/len(train_loader):.4f} | Val Acc: {val_correct/val_total:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
